// å¯¼å…¥æ¨¡å—
import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage, HumanMessage, AIMessage } from 'langchain'
import { ChatPromptTemplate } from "@langchain/core/prompts";
import dotenv from "dotenv";

// åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config();

async function helloWorld() {
  try {
    // æ„å»ºæ¨¡å‹é…ç½®å¯¹è±¡
    const modelConfig = {
      modelName: process.env.OPENAI_MODEL_NAME || "gpt-3.5-turbo",
      temperature: process.env.OPENAI_TEMPERATURE ? parseFloat(process.env.OPENAI_TEMPERATURE) : 0.7,
      apiKey: process.env.OPENAI_API_KEY,
    };
    // åˆ›å»º OpenAI èŠå¤©æ¨¡å‹å®ä¾‹
    const model = new ChatOpenAI(modelConfig);

    const messages1 = [
      new SystemMessage({
        content: 'æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘çš„åå­—å«è´¾ç»´æ–¯'
      }),
      new HumanMessage({
        content: 'è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼'
      })
    ]
    const messages2 = [
      new SystemMessage({
        content: 'æˆ‘æ˜¯ä¸€ä¸ªç¾é£Ÿä¸“å®¶ï¼Œæˆ‘å«æŸ¯å—'
      }),
      new HumanMessage({
        content: 'è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è›‹ç‚’é¥­çš„åšæ³•ï¼'
      })
    ]
    const messages3 = [
      new SystemMessage({
        content: 'æˆ‘æ˜¯ä¸€ä¸ªéŸ³ä¹å®¶ï¼Œæˆ‘çš„åå­—å«æ±¤å§†'
      }),
      new HumanMessage({
        content: 'è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è´å¤šèŠ¬çš„ã€Šæœˆå…‰ã€‹ï¼'
      })
    ]
    const messages = [messages1, messages2, messages3]
    const response = await model.batch(messages)
    response.forEach((res,index) => {
      console.log(res.content,'==================>res',index)
    })
  } catch (error) {
    console.error("âŒ å‘ç”Ÿé”™è¯¯:", error.message);
    if (error.message.includes("API key")) {
      console.log("\nğŸ’¡ æç¤º: è¯·æ£€æŸ¥ä½ çš„ OPENAI_API_KEY æ˜¯å¦æ­£ç¡®é…ç½®");
    }
  }
}

// è¿è¡Œç¨‹åº
helloWorld();
