import { ChatOpenAI } from "@langchain/openai";
// import { OpenAI } from "@langchain/openai";
import dotenv from "dotenv";

dotenv.config();

async function exampleNonChatModel() {
  try {
    if (!process.env.OPENAI_API_KEY) {
      console.error("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");
      return;
    }
    const model = new ChatOpenAI({
      modelName: process.env.OPENAI_MODEL_NAME || "gpt-3.5-turbo",
      temperature: 0.7,
      apiKey: process.env.OPENAI_API_KEY,
    });
    if (process.env.OPENAI_BASE_URL) {
      model.baseURL = process.env.OPENAI_BASE_URL;
    }

    const messageList = [
      {
        role: "user",
        content: "è¯·ä»‹ç»ä¸€ä¸‹é™•è¥¿çœçš„ç‰¹è‰²ç¾é£Ÿ"
      }
    ]
    const response = await model.invoke(messageList);

    console.log("ğŸ§¾ æ¨¡å‹è¾“å‡º:");
    console.log(response);
    console.log(typeof response.content);
    console.log("\n");
  } catch (error) {
    console.error("âŒ å‘ç”Ÿé”™è¯¯:", error.message);
  }
}

// è¿è¡Œç¤ºä¾‹
exampleNonChatModel();


