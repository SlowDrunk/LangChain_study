/**
 * 4.1 è·å–å¤§æ¨¡å‹ç¤ºä¾‹
 * æ¼”ç¤ºå¦‚ä½•åˆå§‹åŒ–å’Œä½¿ç”¨ LangChain çš„å¤§è¯­è¨€æ¨¡å‹
 */
import { ChatOpenAI } from "@langchain/openai";
import dotenv from "dotenv";

dotenv.config();

async function example1() {
  console.log("=== ç¤ºä¾‹ 4.1: è·å–å¤§æ¨¡å‹ ===\n");

  try {
    // æ£€æŸ¥ API Key
    if (!process.env.OPENAI_API_KEY) {
      console.error("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");
      return;
    }

    // åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹
    // è¿™é‡Œä½¿ç”¨ ChatOpenAIï¼Œå®ƒæ”¯æŒå¯¹è¯æ¨¡å¼
    const model = new ChatOpenAI({
      modelName: process.env.OPENAI_MODEL_NAME || "gpt-3.5-turbo",
      temperature: 0.7,
      apiKey: process.env.OPENAI_API_KEY,
    });

    // å¦‚æœé…ç½®äº† baseURLï¼Œæ·»åŠ åˆ°é…ç½®ä¸­
    if (process.env.OPENAI_BASE_URL) {
      model.baseURL = process.env.OPENAI_BASE_URL;
    }

    console.log("âœ… å¤§æ¨¡å‹å·²æˆåŠŸåˆ›å»º");
    console.log(`ğŸ“‹ æ¨¡å‹åç§°: ${process.env.OPENAI_MODEL_NAME || "gpt-3.5-turbo"}\n`);

    // ä½¿ç”¨æ¨¡å‹è¿›è¡Œç®€å•å¯¹è¯
    console.log("ğŸ’¬ æé—®: è¯·ä»‹ç»ä¸€ä¸‹å››å·çœçš„ç‰¹è‰²ç¾é£Ÿ\n");

    const response = await model.invoke([
      {
        role: "user",
        content: "è¯·ä»‹ç»ä¸€ä¸‹å››å·çœçš„ç‰¹è‰²ç¾é£Ÿ"
      }
    ]);

    console.log("ğŸ¤– æ¨¡å‹å›ç­”:");
    console.log(response.content);
    console.log("\n");

  } catch (error) {
    console.error("âŒ å‘ç”Ÿé”™è¯¯:", error.message);
  }
}

// è¿è¡Œç¤ºä¾‹
example1();

